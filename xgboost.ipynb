{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55f94a3c",
   "metadata": {},
   "source": [
    "## XGBoost\n",
    "\n",
    "To ensure consistency and standardization across different models, each model inherits from a base `Model` class. This approach allows for the centralization of methods and code, ensuring that all models follow the same structure.\n",
    "\n",
    "### Base Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db60618",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "\n",
    "MAIN_DIR = \"/kaggle/working/\"\n",
    "\n",
    "\n",
    "class Model(ABC):\n",
    "    @abstractmethod\n",
    "    def fit(self, *args) -> None:\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def evaluate(self, *args) -> float:\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def make_plots(self, *args) -> None:\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def create_confusion_matrix(self, *args) -> None:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f005a3",
   "metadata": {},
   "source": [
    "### Callbacks\n",
    "\n",
    "Once the model structure is defined, it's time to start training. However, for our purposes, we need to define the appropriate callbacks. In the case of XGBoost, these callbacks must follow a specific structure.\n",
    "\n",
    "#### Callback Classes for XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b9077a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import callback\n",
    "from typing import Any\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import DMatrix\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "class XgbCallback(callback.TrainingCallback):\n",
    "    def __init__(self, x_val: pd.DataFrame, y_val: pd.DataFrame) -> None:\n",
    "        super().__init__()\n",
    "        self.x_val = x_val\n",
    "        self.y_val = y_val\n",
    "        self.d_matrix = DMatrix(data=x_val, label=y_val)\n",
    "\n",
    "\n",
    "\n",
    "class F1ScoreCallback(XgbCallback):\n",
    "    def __init__(self, x_val: pd.DataFrame, y_val: pd.DataFrame) -> None:\n",
    "        super().__init__(x_val, y_val)\n",
    "        self.f1_scores = []\n",
    "\n",
    "\n",
    "    def after_iteration(self, model: Any, epoch: int, evals_log: dict[str, dict[str, list[float] | list[tuple[float, float]]]]) -> bool:\n",
    "        y_pred_probs = model.predict(self.d_matrix, iteration_range=(0, epoch + 1))\n",
    "        y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "        f1 = f1_score(self.y_val, y_pred, average='weighted')\n",
    "        self.f1_scores.append(f1)\n",
    "\n",
    "        print(f\"Epoch: {epoch}, F1-Score: {f1:.4f}\")\n",
    "\n",
    "        return False\n",
    "\n",
    "\n",
    "    def get_scores(self) -> list[float]:\n",
    "        return self.f1_scores\n",
    "\n",
    "\n",
    "\n",
    "class HistoryCallback(XgbCallback):\n",
    "    def __init__(self, x_val: pd.DataFrame, y_val: pd.DataFrame) -> None:\n",
    "        super().__init__(x_val, y_val)\n",
    "        self.history = {\n",
    "            \"train_loss\": [],\n",
    "            \"val_loss\": [],\n",
    "            \"train_acc\": [],\n",
    "            \"val_acc\": []\n",
    "        }\n",
    "\n",
    "\n",
    "    def after_iteration(self, model: Any, epoch: int,\n",
    "                        evals_log: dict[str, dict[str, list[float] | list[tuple[float, float]]]]) -> bool:\n",
    "\n",
    "        train_loss = evals_log['train']['mlogloss'][-1] if 'train' in evals_log and 'mlogloss' in evals_log['train'] else None\n",
    "        val_loss = evals_log['validation_0']['mlogloss'][-1] if 'validation_0' in evals_log and 'mlogloss' in evals_log['validation_0'] else None\n",
    "\n",
    "        # Validation accuracy\n",
    "        y_pred_probs = model.predict(self.d_matrix, iteration_range=(0, epoch + 1))\n",
    "        y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "        val_acc = accuracy_score(self.y_val, y_pred)\n",
    "\n",
    "        if 'train' in evals_log and 'accuracy' in evals_log['train']:\n",
    "            train_acc = evals_log['train']['accuracy'][-1]\n",
    "        else:\n",
    "            train_acc = None  # No data\n",
    "\n",
    "        self.history['train_loss'].append(train_loss)\n",
    "        self.history['val_loss'].append(val_loss)\n",
    "        self.history['train_acc'].append(train_acc)\n",
    "        self.history['val_acc'].append(val_acc)\n",
    "\n",
    "        print(f\"Epoch: {epoch}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "        return False\n",
    "\n",
    "\n",
    "    def get_history(self) -> dict:\n",
    "        return self.history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167eacec",
   "metadata": {},
   "source": [
    "### Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430740fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import logging\n",
    "import numpy as np\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from rapidfuzz import process\n",
    "\n",
    "from src.models.model import Model\n",
    "from xgboostCallbacks import F1ScoreCallback, HistoryCallback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc9b950",
   "metadata": {},
   "source": [
    "## Class Description\n",
    "\n",
    "### Overview of Key Parameters:\n",
    "\n",
    "- **vectorizer**: It is used to transform textual or categorical data into a numerical format. In our case, it will be the TF-IDF matrix, which is commonly used to represent text as vectors.\n",
    "- **known_words**: When saving the model, it is necessary to store the words the model was trained on so that when the model is loaded later, the transformation can be applied appropriately.\n",
    "\n",
    "#### Model Parameters\n",
    "- **n_estimators**: Specifies the number of decision trees to be used in the XGBoost model. Increasing this value can improve model accuracy but also increases the training time.\n",
    "- **max_depth**: Sets the maximum depth of each tree. A high depth can lead to overfitting, while a very low depth may limit the model’s ability to learn.\n",
    "- **subsample**: Defines the percentage of samples that will be used to train each tree. This can help avoid overfitting.\n",
    "- **colsample_bytree**: Specifies the percentage of features that will be randomly selected for each tree. This also helps improve the model’s generalization.\n",
    "- **verbosity**: Controls the printing of progress during training, which is useful for debugging and monitoring the training process.\n",
    "\n",
    "### `XGBoostModel` Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f023b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XGBoostModel(Model):\n",
    "\n",
    "    def __init__(self, model_name: str, model_category: str) -> None:\n",
    "        self.model_name = model_name\n",
    "        self.model_category = model_category\n",
    "        self.vectorizer = None\n",
    "        self.known_words = None\n",
    "        self.cm: list[list[float]] = []\n",
    "        self.f1_scores: list[float] = []\n",
    "        self.history = {}\n",
    "        self.model = XGBClassifier(\n",
    "            n_estimators=1000,\n",
    "            max_depth=10,\n",
    "            learning_rate=0.1,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            eval_metric='mlogloss',\n",
    "            early_stopping_rounds=20,\n",
    "            verbosity=3,\n",
    "            # device='cuda'           # Run with GPU\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d3076d",
   "metadata": {},
   "source": [
    "### Preprocessing Words to Known\n",
    "\n",
    "**This step is only required if the model has been previously trained** and we are evaluating it on new data (e.g., when loading the model). This process transforms the input text string into one that most closely matches the `known_words` (the words used to construct the training TF-IDF matrix)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e7855e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_to_known(self, df: pd.DataFrame, column: str) -> pd.DataFrame:\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "        tqdm.pandas()\n",
    "\n",
    "        def process_text(text):\n",
    "            words = text.split()\n",
    "            processed_words = []\n",
    "\n",
    "            for word in words:\n",
    "                lemma = lemmatizer.lemmatize(word.lower())\n",
    "                if lemma in self.known_words:\n",
    "                    processed_words.append(lemma)\n",
    "                else:\n",
    "                    closest_match = process.extractOne(lemma, self.known_words)\n",
    "                    if closest_match[1] > 80:\n",
    "                        processed_words.append(closest_match[0])\n",
    "\n",
    "            return \" \".join(processed_words)\n",
    "\n",
    "        df[column] = df[column].progress_apply(process_text)\n",
    "\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3b7b77",
   "metadata": {},
   "source": [
    "### Converting Input Data to TF-IDF\n",
    "\n",
    "The first step before **starting training** is to **create the TF-IDF matrix**. If the model is being run for the first time, a new vectorizer needs to be created to construct the matrix. However, if the model has been used previously, it must utilize the already saved vectorizer. Finally, the TF-IDF matrix is transformed into a *pandas DataFrame*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d4dbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_tfidf(self, df: pd.DataFrame, column: str, remove_stop_words: bool) -> pd.DataFrame:\n",
    "        if self.vectorizer is None:\n",
    "            if remove_stop_words:\n",
    "                self.vectorizer = TfidfVectorizer(stop_words='english')\n",
    "            else:\n",
    "                self.vectorizer = TfidfVectorizer(stop_words=None)\n",
    "\n",
    "        logging.info(f\"Start preprocess column: {column}\")\n",
    "\n",
    "        tfidf_matrix = self.vectorizer.fit_transform(tqdm(df[column], desc=f'Preprocessing: {column}'))\n",
    "\n",
    "        logging.info(f\"Shape of tfidf_matrix: {tfidf_matrix.shape}\")\n",
    "\n",
    "        tfidf_df = pd.DataFrame.sparse.from_spmatrix(\n",
    "            tfidf_matrix,\n",
    "            columns=self.vectorizer.get_feature_names_out(),\n",
    "            index=df.index\n",
    "        )\n",
    "\n",
    "        df = df.drop(columns=[column])\n",
    "        df = pd.concat([df, tfidf_df], axis=1)\n",
    "\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f9200c",
   "metadata": {},
   "source": [
    "### Adding Missing Columns\n",
    "\n",
    "Since every input matrix must have the same shape as the training matrix, we need to add missing tokens to the already generated matrix (the column is filled with zeros). The matrix must also have tokens in the correct order. Therefore, to ensure reproducibility of matrix creation, each matrix is sorted based on tokens. As the order of tokens in the matrix will change, it's also required to pass the labels correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58baa55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_missing_columns(self, df: pd.DataFrame, label_name: str) -> pd.DataFrame:\n",
    "        existing_words = set(df.columns)\n",
    "\n",
    "        if self.known_words is None:\n",
    "            self.known_words = set(df.columns)\n",
    "\n",
    "        missing_words: set[str] = self.known_words - existing_words\n",
    "\n",
    "        if missing_words:\n",
    "            missing_columns_df = pd.DataFrame(\n",
    "                data=0,\n",
    "                index=df.index,\n",
    "                columns=list(missing_words)\n",
    "            )\n",
    "            df = pd.concat([df, missing_columns_df], axis=1)\n",
    "\n",
    "        sorted_columns = sorted(self.known_words)\n",
    "\n",
    "        if label_name in sorted_columns:\n",
    "            sorted_columns.remove(label_name)\n",
    "        sorted_columns.append(label_name)\n",
    "\n",
    "        df = df[sorted_columns]\n",
    "\n",
    "        return df\n",
    "\n",
    "\n",
    "# Multi-evaluation purpouses only\n",
    "def domain_matches(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df['domain'] = (df['sender'] == df['receiver']).astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b544f21",
   "metadata": {},
   "source": [
    "### Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8757a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(self, x_train: pd.DataFrame, y_train: pd.DataFrame, x_val: pd.DataFrame, y_val: pd.DataFrame) -> None:\n",
    "        if self.known_words is None:\n",
    "            self.known_words = set(x_train.columns)\n",
    "\n",
    "\n",
    "        f1_score_callback = F1ScoreCallback(x_val, y_val)\n",
    "        history_callback = HistoryCallback(x_val, y_val)\n",
    "\n",
    "        self.model.fit(\n",
    "            x_train,\n",
    "            y_train,\n",
    "            verbose=True,\n",
    "            eval_set=[(x_val, y_val)],\n",
    "            callbacks=[f1_score_callback, history_callback]\n",
    "        )\n",
    "\n",
    "        self.f1_scores = f1_score_callback.get_scores()\n",
    "        self.history = history_callback.get_history()\n",
    "\n",
    "\n",
    "def evaluate(self, x_test: pd.DataFrame, y_test: pd.DataFrame) -> float:\n",
    "        y_pred = self.model.predict(x_test, validate_features=False)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        return accuracy\n",
    "\n",
    "\n",
    "def predict_probabilities(self, x_test: pd.DataFrame) -> np.narray:\n",
    "        return self.model.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0b06a7",
   "metadata": {},
   "source": [
    "### Evaluation and plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24503c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_confusion_matrix(self, x_test: pd.DataFrame, y_test: pd.DataFrame) -> None:\n",
    "        y_pred_probs = self.model.predict_proba(x_test)\n",
    "        y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "        y_true = y_test.values.flatten() if hasattr(y_test, 'values') else y_test\n",
    "        self.cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "\n",
    "def make_plots(self) -> None:\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(self.cm, annot=True, fmt='d', cmap='Blues',\n",
    "                    xticklabels=['legal', 'spam', 'phishing', 'fraud'],\n",
    "                    yticklabels=['legal', 'spam', 'phishing', 'fraud'])\n",
    "        plt.xlabel(\"Predicted Labels\")\n",
    "        plt.ylabel(\"True Labels\")\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        plt.savefig(f\"{MAIN_DIR}saved-results/xgb/plots/{self.model_category}/{self.model_name}-conf-matrix.png\")\n",
    "        plt.clf()\n",
    "\n",
    "        epochs = len(self.history[\"train_loss\"])\n",
    "\n",
    "        plt.figure(figsize=(18, 6))\n",
    "\n",
    "        plt.subplot(1, 3, 1)\n",
    "\n",
    "        plt.plot(range(epochs), self.history['val_loss'], label=\"Validation Loss\", color='orange')\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.title(\"Loss over Epochs\")\n",
    "\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.plot(range(epochs), self.history['val_acc'], label=\"Validation Accuracy\", color='orange')\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.legend()\n",
    "        plt.title(\"Accuracy over Epochs\")\n",
    "\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.plot(range(len(self.f1_scores)), self.f1_scores, label=\"Validation F1\", color='orange')\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"F1-Score\")\n",
    "        plt.legend()\n",
    "        plt.title(\"F1-Score over Epochs\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{MAIN_DIR}saved-results/xgb/plots/{self.model_category}/{self.model_name}-accuracy.png\")\n",
    "        plt.clf()\n",
    "\n",
    "        final_accuracy = self.history['val_acc'][-1]\n",
    "        final_f1_score = self.f1_scores[-1]\n",
    "        with open(f\"{MAIN_DIR}{self.model_name}-{self.model_category}\", \"w\") as file:\n",
    "            file.write(f\"Accuracy: {final_accuracy}\\n\")\n",
    "            file.write(f\"F1-Score: {final_f1_score}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74c9b71",
   "metadata": {},
   "source": [
    "### Loading and saving\n",
    "\n",
    "When saving and reading the model, it is necessary to save the known words, which will then be used to create the TF-IDF matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407ed95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(self, model_save_path: str = \"\") -> None:\n",
    "        if model_save_path == \"\":\n",
    "            model_save_path = f\"{MAIN_DIR}/models/xgb/saved/{self.model_category}-{self.model_name}\"\n",
    "\n",
    "        self.model.save_model(f\"{model_save_path}.json\")\n",
    "        with open(f\"{model_save_path}-known-words.json\", \"w\") as f:\n",
    "            json.dump(list(self.known_words), f)\n",
    "\n",
    "\n",
    "def load_model(self, model_load_path: str) -> None:\n",
    "        self.model = XGBClassifier()\n",
    "        self.model.load_model(f\"{model_load_path}.json\")\n",
    "        with open(f\"{model_load_path}-known-words.json\", \"r\") as f:\n",
    "            self.known_words = set(json.load(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3beb1cd",
   "metadata": {},
   "source": [
    "### Multi-Evaluation\n",
    "\n",
    "To achieve the best approach, a multi-model strategy is used, where different models categorize messages based on various features (columns). Each model returns an array of probabilities, and this array is multiplied by the model's accuracy (used as a weight) to favor more accurate models. Finally, the final combined model's plots are saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac750866",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_multi_evaluation(xgb_boost_model_list: list[Tuple[XGBoostModel, str, float, bool, bool]], test_data: pd.DataFrame, test_labels: pd.DataFrame, label_name: str) -> None:\n",
    "\n",
    "    cumulative_probabilities = np.zeros((test_data.shape[0], 4))\n",
    "\n",
    "    for xgb_model, train_column, model_accuracy, remove_stop_words, use_domain in xgb_boost_model_list:\n",
    "        \n",
    "        if use_domain:\n",
    "            final_test_data = domain_matches(test_data)\n",
    "            final_test_data = final_test_data[[train_column]]\n",
    "        else:\n",
    "            temp_data = test_data[[train_column]]\n",
    "            tfidf_matrix = xgb_model.convert_to_tfidf(temp_data, column=train_column,\n",
    "                                                      remove_stop_words=remove_stop_words)\n",
    "            final_test_data = xgb_model.add_missing_columns(tfidf_matrix, label_name)\n",
    "            final_test_data = final_test_data.drop(columns=label_name)\n",
    "        \n",
    "        model_probabilities = xgb_model.model.predict_proba(final_test_data)\n",
    "        cumulative_probabilities += model_probabilities * model_accuracy\n",
    "        \n",
    "    final_predictions = np.argmax(cumulative_probabilities, axis=1)\n",
    "    final_accuracy = accuracy_score(test_labels, final_predictions)\n",
    "    final_f1 = f1_score(test_labels, final_predictions, average='weighted')\n",
    "    cm = confusion_matrix(test_labels, final_predictions)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=['legal', 'spam', 'phishing', 'fraud'],\n",
    "                yticklabels=['legal', 'spam', 'phishing', 'fraud'])\n",
    "    plt.xlabel(\"Predicted Labels\")\n",
    "    plt.ylabel(\"True Labels\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.savefig(f\"{MAIN_DIR}final-{xgb_boost_model_list[0][0].model_category}-conf-matrix.png\")\n",
    "    plt.clf()\n",
    "\n",
    "    with open(f\"{MAIN_DIR}final-{xgb_boost_model_list[0][0].model_category}-accuracy\", \"w\") as file:\n",
    "        file.write(f\"Accuracy: {final_accuracy}\\n\")\n",
    "        file.write(f\"F1-Score: {final_f1}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466cdf4e",
   "metadata": {},
   "source": [
    "### Testing Different Configurations\n",
    "\n",
    "Five different configurations were tested. Based on initial model performance, it was found that models removing stop words performed better, so this approach was applied to all other models. Different types of models worked on different dataset portions due to varying training times and limited hardware resources (GPU P100 on Kaggle).\n",
    "\n",
    "| Model Category           | Used Models                     | Remove Stop Words | Dataset                           |\n",
    "|--------------------------|---------------------------------|-------------------|-----------------------------------|\n",
    "| only-body                | body                            | ❌                | final-with-stop-words.csv         |\n",
    "| only-body-with-stop-words| body                            | ✅                | final.csv                         |\n",
    "| body-subject             | body, subject                   | ✅                | final.csv                         |\n",
    "| body-domain              | body, domain                    | ✅                | final-domain-only.csv             |\n",
    "| full                     | body, domain, subject           | ✅                | final-domain-only.csv             |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e120d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS_PARAMS = [\n",
    "    {\"models\": [(\"body-model\", \"body\", 4_000, False, False)], \"model_category\": \"only-body\", \"dataset\": \"/kaggle/input/xgboost-phishing/final.csv\", \"add_subject\": False, \"add_domain\": False},\n",
    "    {\"models\": [(\"body-model\", \"body\", 4_000, True, False)], \"model_category\": \"only-body-without-stop-words\", \"dataset\": \"/kaggle/input/xgboost-phishing/final-with-stop-words.csv\", \"add_subject\": False, \"add_domain\": False},\n",
    "    {\"models\": [(\"body-model\", \"body\", 4_000, True, False), (\"subject-model\", \"subject\", 16_000, True, False)], \"model_category\": \"body-subject\", \"dataset\": \"/kaggle/input/xgboost-phishing/final.csv\"},\n",
    "    {\"models\": [(\"body-model\", \"body\", 4_000, True, False), (\"domain-model\", \"domain\", 32_000, True, True)], \"model_category\": \"body-domain\", \"dataset\": \"/kaggle/input/xgboost-phishing/final-domain-only.csv\"},\n",
    "    {\"models\": [(\"body-model\", \"body\", 4_000, True, False), (\"domain-model\", \"domain\", 32_000, True, True), (\"subject-model\", \"subject\", 16_000, True, False)], \"model_category\": \"full\", \"dataset\": \"/kaggle/input/xgboost-phishing/final-domain-only.csv\"}\n",
    "]\n",
    "\n",
    "\n",
    "for param in MODELS_PARAMS:\n",
    "\n",
    "    models: list[Tuple[XGBoostModel, float]] = []\n",
    "\n",
    "    data = pd.read_csv(param[\"dataset\"])\n",
    "    label_column = \"$label\"\n",
    "    data = data.rename(columns={'label': label_column})\n",
    "\n",
    "    for model_name, train_column, data_length, remove_stop_words, use_domain in param[\"models\"]:\n",
    "\n",
    "        input_data = data.sample(n=data_length, random_state=43)\n",
    "        xgb_model = XGBoostModel(model_name, param[\"model_category\"])\n",
    "\n",
    "        if use_domain:\n",
    "            train_data = domain_matches(input_data)\n",
    "            train_labels = train_data[[label_column]]\n",
    "            train_data = train_data[[train_column]]\n",
    "        else:\n",
    "            input_data = input_data[[train_column, label_column]]\n",
    "            tfidf_matrix = xgb_model.convert_to_tfidf(input_data, column=train_column, remove_stop_words=remove_stop_words)\n",
    "            train_data = xgb_model.add_missing_columns(tfidf_matrix, label_column)\n",
    "            train_labels = train_data[[label_column]]\n",
    "            train_data = train_data.drop(columns=[label_column])\n",
    "\n",
    "        X_train, X_temp, Y_train, Y_temp = train_test_split(train_data, train_labels, test_size=0.3, random_state=28)\n",
    "        X_val, X_test, Y_val, Y_test = train_test_split(X_temp, Y_temp, test_size=0.5, random_state=28)\n",
    "\n",
    "        xgb_model.fit(X_train, Y_train, X_val, Y_val)\n",
    "        xgb_model.create_confusion_matrix(X_test, Y_test)\n",
    "        xgb_model.make_plots()\n",
    "        xgb_model.save()\n",
    "\n",
    "        print(hash(frozenset(xgb_model.known_words)))\n",
    "        model_accuracy = xgb_model.evaluate(X_test, Y_test)\n",
    "\n",
    "        print(model_accuracy)\n",
    "        models.append((xgb_model, train_column, model_accuracy, remove_stop_words, use_domain))\n",
    "\n",
    "    test_data = data.sample(n=data_length, random_state=43)\n",
    "    test_labels = test_data[[label_column]]\n",
    "    test_data = test_data.drop(columns=[label_column])\n",
    "    perform_multi_evaluation(models, test_data, test_labels, label_column)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
