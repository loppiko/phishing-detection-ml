{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2df62fc0",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecadd6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "MAIN_DIR = \"/kaggle/working/\"\n",
    "\n",
    "\n",
    "class Model(ABC):\n",
    "    @abstractmethod\n",
    "    def fit(self, *args) -> None:\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def evaluate(self, *args) -> float:\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def make_plots(self, *args) -> None:\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def create_confusion_matrix(self, *args) -> None:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39867169",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c1def0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, Callback\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "class F1ScoreCallback(Callback):\n",
    "    def __init__(self, x_val, y_val):\n",
    "        self.x_val = x_val\n",
    "        self.y_val = y_val\n",
    "        self.f1_scores = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        y_pred = np.argmax(self.model.predict(self.x_val), axis=1)\n",
    "        y_true = np.argmax(self.y_val, axis=1)\n",
    "        f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "        self.f1_scores.append(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e75102",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c36e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, Callback\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abe6976",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "Preprocessing involves converting the 'sender' and 'receiver' columns (if applicable) into a 'domain' column. This new column contains information about whether the sender and receiver domains match (True if they match, False otherwise). After that, the 'domain' column is added to the final training column along with the subject (if applicable). No additional steps are required.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6bea9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df: pd.DataFrame, add_subject: bool, add_domain: bool) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        combined_data = df['body']\n",
    "\n",
    "        if add_subject:\n",
    "            combined_data = df['subject'] + \" \" + combined_data\n",
    "        if add_domain:\n",
    "            df['domain'] = (df['sender'] == df['receiver']).astype(int)\n",
    "\n",
    "            combined_data = df['domain'].astype(str) + \" \" + combined_data\n",
    "\n",
    "        return combined_data.values, df['label'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822af46a",
   "metadata": {},
   "source": [
    "### Opis parametrów modelu\n",
    "\n",
    "- **Embedding** - przekształca liczby całkowite reprezentujące słowa w wektory o stałej długości\n",
    "- **LSTM** - Warstwa LSTM\n",
    "- **Dropout** - Zapobieganie przeuczeniu poprzez zerowanie 50% jednostek wejściowych z wektora\n",
    "- **Dense** - Wprowadzenie nieliniowości do modelu za pomocą funkcji Relu lub przewidywanie jednej z 4 klas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151fbebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModelAdvanced():\n",
    "\n",
    "    def __init__(self, model_name: str):\n",
    "        self.history = None\n",
    "        self.cm: list[list[float]] = []\n",
    "        self.f1_scores: list[float] = []\n",
    "\n",
    "        self.model_name = model_name\n",
    "        self.model = Sequential([\n",
    "            Embedding(input_dim=5000, output_dim=128),\n",
    "            LSTM(128),\n",
    "            Dropout(0.5),\n",
    "            Dense(64, activation='relu'),\n",
    "            Dropout(0.5),\n",
    "            Dense(4, activation='softmax')\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603e4ea7",
   "metadata": {},
   "source": [
    "### Training model\n",
    "\n",
    "Do trenowania modelu zamiast oversamplingu zostały wykorzystane dynamicznie obliczane wagi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5fe5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(self, x_train: pd.DataFrame, y_train: pd.DataFrame, x_val: pd.DataFrame, y_val: pd.DataFrame):\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True)\n",
    "\n",
    "        class_weights = compute_class_weight(\n",
    "            class_weight='balanced',\n",
    "            classes=np.unique(np.argmax(y_train, axis=1)),\n",
    "            y=np.argmax(y_train, axis=1)\n",
    "        )\n",
    "\n",
    "        class_weights_dict = dict(enumerate(class_weights))\n",
    "        f1_callback = F1ScoreCallback(x_val, y_val)\n",
    "\n",
    "        self.model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        self.history = self.model.fit(x_train, y_train, epochs=35, batch_size=16, validation_split=0.2, callbacks=[early_stopping, f1_callback], class_weight=class_weights_dict)\n",
    "\n",
    "        self.f1_scores = f1_callback.f1_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a83bc09",
   "metadata": {},
   "source": [
    "### Evaluation and plots\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd93b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(self, x_test: pd.DataFrame, y_test: pd.DataFrame) -> None:\n",
    "        loss, accuracy = self.model.evaluate(x_test, y_test)\n",
    "        print(f\"Loss: {loss}, Accuracy: {accuracy}\")\n",
    "\n",
    "\n",
    "def create_confusion_matrix(self, x_test: pd.DataFrame, y_test: pd.DataFrame):\n",
    "        y_pred_probs = self.model.predict(x_test)\n",
    "        y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "        y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "        self.cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "\n",
    "def make_plots(self) -> None:\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(self.cm, annot=True, fmt='d', cmap='Blues',\n",
    "                    xticklabels=['legal', 'spam', 'phishing', 'fraud'],\n",
    "                    yticklabels=['legal', 'spam', 'phishing', 'fraud'])\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('True')\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.savefig(f\"{MAIN_DIR}{self.model_name}-conf-matrix.png\")\n",
    "        plt.clf()\n",
    "\n",
    "        accuracy = self.history.history['accuracy']\n",
    "        val_accuracy = self.history.history['val_accuracy']\n",
    "        loss = self.history.history['loss']\n",
    "        val_loss = self.history.history['val_loss']\n",
    "\n",
    "        plt.figure(figsize=(18, 6))\n",
    "\n",
    "        # Accuracy\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.plot(accuracy, label='Training Accuracy')\n",
    "        plt.plot(val_accuracy, label='Validation Accuracy')\n",
    "        plt.title('Accuracy over Epochs')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend()\n",
    "\n",
    "        # Loss\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.plot(loss, label='Training Loss')\n",
    "        plt.plot(val_loss, label='Validation Loss')\n",
    "        plt.title('Loss over Epochs')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "\n",
    "        # F1-score plot\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.plot(range(1, len(self.f1_scores) + 1), self.f1_scores, label='Validation F1-Score', color='orange')\n",
    "        plt.title('F1-Score over Epochs')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('F1-Score')\n",
    "        plt.legend()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{MAIN_DIR}{self.model_name}-accuracy.png\")\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "        final_accuracy = val_accuracy[-1]\n",
    "        final_f1_score = self.f1_scores[-1]\n",
    "        with open(f\"{MAIN_DIR}{self.model_name}-final-metrics.txt\", \"w\") as file:\n",
    "            file.write(f\"Accuracy: {final_accuracy}\\n\")\n",
    "            file.write(f\"F1-Score: {final_f1_score}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ef8abe",
   "metadata": {},
   "source": [
    "### Saving and loading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13665d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saving_model(self, save_path: str = \"\") -> None:\n",
    "        if save_path:\n",
    "            self.model.save(save_path)\n",
    "            print(f\"Model saved to {save_path}\")\n",
    "        else:\n",
    "            self.model.save(f\"{MAIN_DIR}{self.model_name}-model.keras\")\n",
    "            print(f\"Model saved to {MAIN_DIR}{self.model_name}-model.keras\")\n",
    "\n",
    "\n",
    "@staticmethod\n",
    "def loading_model(load_path: str):\n",
    "        return load_model(load_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce5516d",
   "metadata": {},
   "source": [
    "### Testing Different Variants\n",
    "\n",
    "For each model, a Tokenizer was used, which processes the 5000 most frequent words, and then transforms them into numerical format. The text is then padded, and a maximum length is applied. Since the initial models performed better with the `stop_words` parameter, this approach was used for training the remaining models.\n",
    "\n",
    "| model-name        | used columns      | Remove stop words | dataset                           |\n",
    "|-------------------|-------------------|--------------------|-----------------------------------|\n",
    "| only-body         | body              | ❌                 | final-with-stop-words.csv         |\n",
    "| stop-words-body   | body              | ✅                 | final.csv                         |\n",
    "| body-subject-stop | body, subject     | ❌                 | final-with-stop-words.csv         |\n",
    "| body-domain-stop  | body, domain      | ❌                 | final-with-stop-words-domain-only.csv |\n",
    "| full-data-stop    | body, domain, subject | ❌             | final-with-stop-words-domain-only.csv |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0409f281",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lstm_model(lstm_model: LSTMModelAdvanced, train_data: np.ndarray, train_labels: np.ndarray, max_length: int, model_save_path: str = \"\") -> None:\n",
    "    tokenizer = Tokenizer(num_words=5000)\n",
    "    tokenizer.fit_on_texts(train_data)\n",
    "\n",
    "    sequences = tokenizer.texts_to_sequences(train_data)\n",
    "\n",
    "    y_train_one_hot = to_categorical(train_labels, num_classes=4)\n",
    "\n",
    "    padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post')\n",
    "\n",
    "    X_train, X_temp, Y_train, Y_temp = train_test_split(padded_sequences, y_train_one_hot, test_size=0.3, random_state=28)\n",
    "    X_val, X_test, Y_val, Y_test = train_test_split(X_temp, Y_temp, test_size=0.5, random_state=28)\n",
    "\n",
    "    lstm_model.fit(X_train, Y_train, X_val, Y_val)\n",
    "    lstm_model.evaluate(X_test, Y_test)\n",
    "    lstm_model.create_confusion_matrix(X_test, Y_test)\n",
    "    lstm_model.make_plots()\n",
    "    lstm_model.saving_model(model_save_path)\n",
    "\n",
    "\n",
    "\n",
    "MODELS_PARAMS = [\n",
    "    {\"model_name\": \"only-body\", \"dataset\": \"/kaggle/input/final-csv/final.csv\", \"add_subject\": False, \"add_domain\": False},\n",
    "    {\"model_name\": \"stop-words-body\", \"dataset\": \"/kaggle/input/final-2-csv/final-with-stop-words.csv\", \"add_subject\": False, \"add_domain\": False},\n",
    "    {\"model_name\": \"body-subject-stop\", \"dataset\": \"/kaggle/input/final-2-csv/final-with-stop-words.csv\", \"add_subject\": True, \"add_domain\": False},\n",
    "    {\"model_name\": \"body-domain-stop\", \"dataset\": \"/kaggle/input/final-2-csv/final-with-stop-words-domain-only.csv\", \"add_subject\": False, \"add_domain\": True},\n",
    "    {\"model_name\": \"full-data-stop\", \"dataset\": \"/kaggle/input/final-2-csv/final-with-stop-words-domain-only.csv\", \"add_subject\": True, \"add_domain\": True}\n",
    "]\n",
    "\n",
    "\n",
    "for params in MODELS_PARAMS:\n",
    "    data = pd.read_csv(params[\"dataset\"])\n",
    "    numpy_data, labels = preprocess_data(data, add_subject=params[\"add_subject\"], add_domain=params[\"add_domain\"])\n",
    "\n",
    "    body_max_length = 1000\n",
    "\n",
    "    body_model = LSTMModelAdvanced(params['model_name'])\n",
    "    train_lstm_model(body_model, numpy_data, labels, body_max_length)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
